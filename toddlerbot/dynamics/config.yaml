device: 0
seed: 3407
run_mode: train

model:
  observation_size: 83
  action_size: 12
  hidden_layers: [128, 128, 128]

data:
  num_envs: 1024
  num_test_envs: 1024
  num_test_steps: 100
  step_batch_size: 32
  env_batch_size: 512
  num_workers: 8
  horizon: 5
  history: 5
  run_name: "toddlerbot_2xm_walk_ppo_PPOConfig.num_timesteps=3000000_20250315_162415_torch"

train:
  optimizer:
    _target_: torch.optim.AdamW
    lr: 1e-3
    weight_decay: 5e-3

  lr_scheduler:
  finetune: False

  loss_func:
    _target_: torch.nn.MSELoss
    reduction: mean

  trainer:
    _target_:  pytorch_lightning.trainer.Trainer
    strategy: 'auto'
    max_epochs: 50
    check_val_every_n_epoch: True
    val_check_interval: 
    log_every_n_steps: 10
    limit_val_batches: 1

    enable_model_summary: false

    callbacks:
    - _target_: pytorch_lightning.callbacks.ModelCheckpoint
      filename: "{epoch}-{val_loss:.4f}"
      monitor: 'val_loss'
      mode: 'min'
      save_top_k: 3
      verbose: true
      # - _target_: pytorch_lightning.callbacks.EarlyStopping
      # monitor: 'val_loss'
      # min_delta: 0.0001
      # patience: 10
      # verbose: True
      # mode: "min"

hydra:
  sweep:
    dir: "results/dynamics_model_${now:%Y%m%d_%H%M%S}"
  run:
    dir: "results/dynamics_model_${now:%Y%m%d_%H%M%S}"
